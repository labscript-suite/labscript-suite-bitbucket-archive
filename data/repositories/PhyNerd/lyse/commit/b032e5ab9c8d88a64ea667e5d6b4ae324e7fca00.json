{"rendered": {"message": {"raw": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "markup": "markdown", "html": "<p>Performance optimisation.</p>\n<ul>\n<li>\n<p>lookup rows in dataframe by filepath using a dictionary cache rather<br />\n  than searching the dataframe. This removes the need for the method<br />\n  get_model_row_by_filepath(), so it has been removed and the dictionary used<br />\n  directly.</p>\n</li>\n<li>\n<p>Remove redundant getting of the row index again for the Qt model - it is<br />\n  the same row as the dataframe</p>\n</li>\n<li>\n<p>Avoid setting the text of a QStandardItem twice by only creating it once<br />\n  the text it should have is known</p>\n</li>\n<li>\n<p>Add an argument to renumber_rows() that allows it to only renumber recent<br />\n  rows for the case that new rows have been added and don't have numbers yet<br />\n  but the existing row numbers are still valid</p>\n</li>\n<li>\n<p>Modify batch processing of shot files to use a dynamic batch size, with<br />\n  larger batches the more shots lyse has loaded. This is a good tradeoff<br />\n  between GUI responsiveness when there are a small number of shot files<br />\n  and speed when loading a large number of shot files. The batch size is 1/3<br />\n  of the number of shots. Larger batch sizes mean less redundant concatenation<br />\n  of dataframes.</p>\n</li>\n<li>\n<p>Modify the progress bar message to say when it's reading shot files<br />\n  vs concatenating dataframes vs updating the filebox GUI.</p>\n</li>\n</ul>", "type": "rendered"}}, "hash": "b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00", "repository": {"links": {"self": {"href": "data/repositories/PhyNerd/lyse.json"}, "html": {"href": "#!/PhyNerd/lyse"}, "avatar": {"href": "data/bytebucket.org/ravatar/{d53abe9e-de63-48eb-9cc5-379fd9cdfed9}ts=python"}}, "type": "repository", "name": "lyse", "full_name": "PhyNerd/lyse", "uuid": "{d53abe9e-de63-48eb-9cc5-379fd9cdfed9}"}, "links": {"self": {"href": "data/repositories/PhyNerd/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00.json"}, "comments": {"href": "data/repositories/PhyNerd/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/comments_page=1.json"}, "patch": {"href": "https://api.bitbucket.org/2.0/repositories/PhyNerd/lyse/patch/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "html": {"href": "#!/PhyNerd/lyse/commits/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "diff": {"href": "https://api.bitbucket.org/2.0/repositories/PhyNerd/lyse/diff/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "approve": {"href": "https://api.bitbucket.org/2.0/repositories/PhyNerd/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/approve"}, "statuses": {"href": "data/repositories/PhyNerd/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/statuses_page=1.json"}}, "author": {"raw": "chrisjbillington", "type": "author"}, "summary": {"raw": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "markup": "markdown", "html": "<p>Performance optimisation.</p>\n<ul>\n<li>\n<p>lookup rows in dataframe by filepath using a dictionary cache rather<br />\n  than searching the dataframe. This removes the need for the method<br />\n  get_model_row_by_filepath(), so it has been removed and the dictionary used<br />\n  directly.</p>\n</li>\n<li>\n<p>Remove redundant getting of the row index again for the Qt model - it is<br />\n  the same row as the dataframe</p>\n</li>\n<li>\n<p>Avoid setting the text of a QStandardItem twice by only creating it once<br />\n  the text it should have is known</p>\n</li>\n<li>\n<p>Add an argument to renumber_rows() that allows it to only renumber recent<br />\n  rows for the case that new rows have been added and don't have numbers yet<br />\n  but the existing row numbers are still valid</p>\n</li>\n<li>\n<p>Modify batch processing of shot files to use a dynamic batch size, with<br />\n  larger batches the more shots lyse has loaded. This is a good tradeoff<br />\n  between GUI responsiveness when there are a small number of shot files<br />\n  and speed when loading a large number of shot files. The batch size is 1/3<br />\n  of the number of shots. Larger batch sizes mean less redundant concatenation<br />\n  of dataframes.</p>\n</li>\n<li>\n<p>Modify the progress bar message to say when it's reading shot files<br />\n  vs concatenating dataframes vs updating the filebox GUI.</p>\n</li>\n</ul>", "type": "rendered"}, "participants": [], "parents": [{"hash": "b90281ed62967638da073340fee577d2e532c1dd", "type": "commit", "links": {"self": {"href": "data/repositories/PhyNerd/lyse/commit/b90281ed62967638da073340fee577d2e532c1dd.json"}, "html": {"href": "#!/PhyNerd/lyse/commits/b90281ed62967638da073340fee577d2e532c1dd"}}}], "date": "2018-02-26T06:02:36+00:00", "message": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "type": "commit", "git_hash": "86c988eb5edf68000c5e052a749ccddb1fca0519", "tags": null, "branches": "feature"}