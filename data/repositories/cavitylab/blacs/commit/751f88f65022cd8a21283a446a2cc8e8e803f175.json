{"rendered": {"message": {"raw": "Appending data at end of acquisition is now very fast!\n\nWriting to h5file is the slowest part.\n\nCan handle 32 channels @ 20kHz for 120s.\nCan't handle the same for 180s. I catch an exception, but there is no error message. Might be to do with the size of the numpy array? May have to split, and write consecutive numpy arrays to the h5 file", "markup": "markdown", "html": "<p>Appending data at end of acquisition is now very fast!</p>\n<p>Writing to h5file is the slowest part.</p>\n<p>Can handle 32 channels @ 20kHz for 120s.<br />\nCan't handle the same for 180s. I catch an exception, but there is no error message. Might be to do with the size of the numpy array? May have to split, and write consecutive numpy arrays to the h5 file</p>", "type": "rendered"}}, "hash": "751f88f65022cd8a21283a446a2cc8e8e803f175", "repository": {"links": {"self": {"href": "data/repositories/cavitylab/blacs.json"}, "html": {"href": "#!/cavitylab/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{95ce113a-2d94-42de-b9fb-c31ba362c5f1}ts=python"}}, "type": "repository", "name": "BLACS", "full_name": "cavitylab/blacs", "uuid": "{95ce113a-2d94-42de-b9fb-c31ba362c5f1}"}, "links": {"self": {"href": "data/repositories/cavitylab/blacs/commit/751f88f65022cd8a21283a446a2cc8e8e803f175.json"}, "comments": {"href": "data/repositories/cavitylab/blacs/commit/751f88f65022cd8a21283a446a2cc8e8e803f175/comments_page=1.json"}, "patch": {"href": "https://api.bitbucket.org/2.0/repositories/cavitylab/blacs/patch/751f88f65022cd8a21283a446a2cc8e8e803f175"}, "html": {"href": "#!/cavitylab/blacs/commits/751f88f65022cd8a21283a446a2cc8e8e803f175"}, "diff": {"href": "https://api.bitbucket.org/2.0/repositories/cavitylab/blacs/diff/751f88f65022cd8a21283a446a2cc8e8e803f175"}, "approve": {"href": "https://api.bitbucket.org/2.0/repositories/cavitylab/blacs/commit/751f88f65022cd8a21283a446a2cc8e8e803f175/approve"}, "statuses": {"href": "data/repositories/cavitylab/blacs/commit/751f88f65022cd8a21283a446a2cc8e8e803f175/statuses_page=1.json"}}, "author": {"raw": "pstarkey", "type": "author", "user": {"display_name": "Philip Starkey", "uuid": "{48af65db-e5fc-459c-a7eb-52eb1f9a5690}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B48af65db-e5fc-459c-a7eb-52eb1f9a5690%7D"}, "html": {"href": "https://bitbucket.org/%7B48af65db-e5fc-459c-a7eb-52eb1f9a5690%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dc318537facc47ebe1ae98a7aabacecfd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsPS-0.png"}}, "nickname": "pstarkey", "type": "user", "account_id": "557058:52a111e4-40da-4441-9143-417f95f2db97"}}, "summary": {"raw": "Appending data at end of acquisition is now very fast!\n\nWriting to h5file is the slowest part.\n\nCan handle 32 channels @ 20kHz for 120s.\nCan't handle the same for 180s. I catch an exception, but there is no error message. Might be to do with the size of the numpy array? May have to split, and write consecutive numpy arrays to the h5 file", "markup": "markdown", "html": "<p>Appending data at end of acquisition is now very fast!</p>\n<p>Writing to h5file is the slowest part.</p>\n<p>Can handle 32 channels @ 20kHz for 120s.<br />\nCan't handle the same for 180s. I catch an exception, but there is no error message. Might be to do with the size of the numpy array? May have to split, and write consecutive numpy arrays to the h5 file</p>", "type": "rendered"}, "participants": [], "parents": [{"hash": "b6d6ad9c79e0980ebaea7885b7230b90d57f1ffc", "type": "commit", "links": {"self": {"href": "data/repositories/cavitylab/blacs/commit/b6d6ad9c79e0980ebaea7885b7230b90d57f1ffc.json"}, "html": {"href": "#!/cavitylab/blacs/commits/b6d6ad9c79e0980ebaea7885b7230b90d57f1ffc"}}}], "date": "2011-10-17T08:01:06+00:00", "message": "Appending data at end of acquisition is now very fast!\n\nWriting to h5file is the slowest part.\n\nCan handle 32 channels @ 20kHz for 120s.\nCan't handle the same for 180s. I catch an exception, but there is no error message. Might be to do with the size of the numpy array? May have to split, and write consecutive numpy arrays to the h5 file", "type": "commit", "git_hash": "9a9fe1f2b40277a9959a2b4c5ea3a9d870b8f32d", "tags": null, "branches": "default"}