{"pagelen": 100, "values": [{"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55160004.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55160004"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "created_on": "2019-12-08T19:18:52.731060+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 55160004}, {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55160011.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55160011"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "created_on": "2019-12-08T19:19:47.068362+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 55160011}, {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55160016.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55160016"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": null, "markup": "markdown", "html": "", "type": "rendered"}, "created_on": "2019-12-08T19:20:41.688640+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 55160016}, {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55162159.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55162159"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": "I suspect another slow point is the NI cards with multiple worker processes \\(which is most of them I think\\).\n\nThere is no particular reason why communication with each worker process needs to be serialised, other than the fact that it\u2019s a bit more complicated to implement.\n\nTo change this we would need to rewrite the mainloop in the tab base class \\(maybe taking advantage of some Python3 coroutine features?\\). The `yield` calls in GUI methods would need to \\(optionally, for backwards compatibility\\) return \u201cpromises\u201d \\(a concept from JavaScript I think\u2026effectively an object you query later for the work and equivalent to what we do with `inmain_later`\\). That way, all worker processes can do work simultaneously, speeding up the transitions.\n\nThis will be particularly effective if we cache the HDF5 file.", "markup": "markdown", "html": "<p>I suspect another slow point is the NI cards with multiple worker processes (which is most of them I think).</p>\n<p>There is no particular reason why communication with each worker process needs to be serialised, other than the fact that it\u2019s a bit more complicated to implement.</p>\n<p>To change this we would need to rewrite the mainloop in the tab base class (maybe taking advantage of some Python3 coroutine features?). The <code>yield</code> calls in GUI methods would need to (optionally, for backwards compatibility) return \u201cpromises\u201d (a concept from JavaScript I think\u2026effectively an object you query later for the work and equivalent to what we do with <code>inmain_later</code>). That way, all worker processes can do work simultaneously, speeding up the transitions.</p>\n<p>This will be particularly effective if we cache the HDF5 file.</p>", "type": "rendered"}, "created_on": "2019-12-09T01:40:42.098964+00:00", "user": {"display_name": "Philip Starkey", "uuid": "{0147401a-13ed-4e39-a0d0-63108c18738b}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B0147401a-13ed-4e39-a0d0-63108c18738b%7D"}, "html": {"href": "https://bitbucket.org/%7B0147401a-13ed-4e39-a0d0-63108c18738b%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/fa0698c306b3470c00717c146b5296e9d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsPS-0.png"}}, "nickname": "philipstarkey", "type": "user", "account_id": "557058:2f99420c-1dbd-4837-952c-82c421b8fbdd"}, "updated_on": null, "type": "issue_comment", "id": 55162159}, {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55173609.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55173609"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": "Ah, that's a good point. I think that by itself could be accommodated in the current framework by just having the coroutine yield a dict of jobs to do for each worker, instead of just one - then the mainloop can wait on them all simultaneously with a `poll` or `select` call. The fact that each worker is only running one function at a time means it's not that different to what we have now. Writing data to HDF5 files at the same time as setting up the next shot though, that would be workers doing two things at once, so would be more involved (though not really solved by async/await since it's cross-process, and since we would want the multiple worker tasks to be executing in true parallel, not just the single-threaded concurrency that coroutines get you. Speaking of this, if h5py still holds the GIL these days for I/O, then we won't get a speedup by running it in a separate thread, we'll need to pipe the data to another process...hm...maybe have to write in bulk in a separate process as well as read. Yikes.).\n\nI'm currently a bit averse to async/await when threads suffice. I investigated it for the new zlock server and it was a) overkill in terms of complexity and b) not very performant. What we're doing with the `yield`-based generators in the GUI is definitely what's intended to be covered by async/await, but our needs are modest and I suspect we will still want control over our own mainloop as we do now. We could switch to the new syntax though - I believe you can use your own event loop and have async/await syntax be a drop-in replacement for how our coroutines are defined presently. There are also more performant 3rd-party event loops available. Worth thinking about though, I can't say my aversion is well-justified.", "markup": "markdown", "html": "<p>Ah, that's a good point. I think that by itself could be accommodated in the current framework by just having the coroutine yield a dict of jobs to do for each worker, instead of just one - then the mainloop can wait on them all simultaneously with a <code>poll</code> or <code>select</code> call. The fact that each worker is only running one function at a time means it's not that different to what we have now. Writing data to HDF5 files at the same time as setting up the next shot though, that would be workers doing two things at once, so would be more involved (though not really solved by async/await since it's cross-process, and since we would want the multiple worker tasks to be executing in true parallel, not just the single-threaded concurrency that coroutines get you. Speaking of this, if h5py still holds the GIL these days for I/O, then we won't get a speedup by running it in a separate thread, we'll need to pipe the data to another process...hm...maybe have to write in bulk in a separate process as well as read. Yikes.).</p>\n<p>I'm currently a bit averse to async/await when threads suffice. I investigated it for the new zlock server and it was a) overkill in terms of complexity and b) not very performant. What we're doing with the <code>yield</code>-based generators in the GUI is definitely what's intended to be covered by async/await, but our needs are modest and I suspect we will still want control over our own mainloop as we do now. We could switch to the new syntax though - I believe you can use your own event loop and have async/await syntax be a drop-in replacement for how our coroutines are defined presently. There are also more performant 3rd-party event loops available. Worth thinking about though, I can't say my aversion is well-justified.</p>", "type": "rendered"}, "created_on": "2019-12-09T16:53:36.828193+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 55173609}, {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53/comments/55173991.json"}, "html": {"href": "#!/labscript_suite/blacs/issues/53#comment-55173991"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs/issues/53.json"}}, "type": "issue", "id": 53, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "title": "Ways of speeding up cycle time. Pipelining, readahead, removing redundant steps."}, "content": {"raw": "Progress on the h5py GIL front!\n\nhttps://github.com/h5py/h5py/pull/1412\n\nhttps://github.com/h5py/h5py/pull/1453\n\nIt sounds like soon threading will be sufficient to do HDF5 I/O blocking other threads. Good. Writing a server just to do HDF5 writes would be so far from what HDF5 is supposed to be that we might as well be using a traditional database at that point...\n\nEdit: Just tested with development h5py from github, and indeed threads can run during IO! This is great. It will be in the next release, which might be early to mid 2020 judging by their past releases.", "markup": "markdown", "html": "<p>Progress on the h5py GIL front!</p>\n<p><a href=\"https://github.com/h5py/h5py/pull/1412\" rel=\"nofollow\" class=\"ap-connect-link\">https://github.com/h5py/h5py/pull/1412</a></p>\n<p><a href=\"https://github.com/h5py/h5py/pull/1453\" rel=\"nofollow\" class=\"ap-connect-link\">https://github.com/h5py/h5py/pull/1453</a></p>\n<p>It sounds like soon threading will be sufficient to do HDF5 I/O blocking other threads. Good. Writing a server just to do HDF5 writes would be so far from what HDF5 is supposed to be that we might as well be using a traditional database at that point...</p>\n<p>Edit: Just tested with development h5py from github, and indeed threads can run during IO! This is great. It will be in the next release, which might be early to mid 2020 judging by their past releases.</p>", "type": "rendered"}, "created_on": "2019-12-09T17:28:21.087674+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": "2019-12-09T18:03:59.763654+00:00", "type": "issue_comment", "id": 55173991}], "page": 1, "size": 6}