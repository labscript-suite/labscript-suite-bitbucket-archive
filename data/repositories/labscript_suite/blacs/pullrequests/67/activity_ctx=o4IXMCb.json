{"pagelen": 50, "values": [{"update": {"description": "* Add support for remote workers.\r\n    Raise NotImplementedError on request for remote GUI, or multi-hop remote\r\n    workers, neither of which are supported quite yet.\r\n    Require labscript_utils 2.12.3, which has fixes for remote workers\r\n    and which in turn relies on a zprocess version with other required fixes.\r\n\r\n* Convert h5 filepaths to network agnostic before sending them to worker\r\n    processes for transition_to_buffered.\r\n\r\n    Only do this if the device is actually a remote device. This way, it is backward\r\n    compatible with device not expecting remote paths. Workers that are updated to\r\n    support being remote workers will need to check `self.is_remote` before calling\r\n    `path_to_local`, since if running locally the path with continue to be a local one.\r\n\r\n    Bump patch version so that labscript devices can depend on this new behaviour.\r\n\r\nThis PR requires labscript_utils [pull request 77](#!/labscript_suite/labscript_utils/pull-requests/77/), and so should be merged after it, with the version check updated to reflect whatever version number that PR ends up being tagged as.\r\n\r\nIt is not currently obvious how to setup and run remote workers. I will need to document how to start the remote process server, including configuring a security key.\r\n\r\nFor now, if anyone wants to test, this is my test script:\r\n```\r\nfrom labscript import *\r\nfrom labscript_devices.PulseBlaster import PulseBlaster\r\nfrom labscript_devices.IMAQdxCamera.labscript_devices import IMAQdxCamera\r\n\r\nPulseBlaster('pulseblaster')\r\nTrigger('camera_trigger', pulseblaster.direct_outputs, 'flag 0')\r\nRemoteBLACS('test_remote', 'localhost')\r\nIMAQdxCamera(\r\n    'camera', camera_trigger, 'trigger', serial_number=0xDEADBEEF, worker=test_remote\r\n)\r\nIMAQdxCamera('camera2', camera_trigger, 'trigger', serial_number=0xDEADBEEF)\r\nstart()\r\n\r\ncamera.expose(1, 'test', trigger_duration=0.2)\r\ncamera2.expose(1, 'test', trigger_duration=0.2)\r\n\r\nstop(2)\r\n```\r\n\r\nAnd to start a zprocess remote server, you will need to run `python -m labscript_utils.remote` on the remote computer.\r\n\r\nYou will want to configure security - I think the remote server refuses to run presently unless you have either set\r\n```\r\n[security]\r\nshared_secret=<path to shared secret file>\r\n```\r\nor\r\n[security]\r\nallow_insecure = True\r\n```\r\n\r\nin your labconfig.\r\n\r\nA new shared secret file can be generated with `python -m zprocess.makesecret`. Obviously all labconfigs on the computers that need to communicate with each other will need to have the same shared secret file.\r\n\r\nOne complication of enabling encryption is that it is enabled for all zmq communication in the labscript suite. This includes zlock. To start zlock with labscript-suite security settings, it needs to be started as `python -m labscript_utils.zlock` instead of `python -m zprocess.locking` or `python -m zprocess.zlock` (the former is an alias for the latter nowadays). However, if you look at `labscript_utils.zlock` you can see that all it is doing is reading labconfig and calling `python -m zprocess.zlock <command line args>`, so if running zlock on a separate computer without the labscript suite, it is easy enough to pass in the required shared secret on the command line.  `python -m zprocess.zlock -h` will list command line options for running a zlock server.\r\n\r\nSo you will need to restart zlock servers with encryption enabled, furthermore, you will need to kill zlog servers that may still be running after turning encryption on, as they will need to be started again with encryption.\r\n\r\nThe reason zlock is a complication is that non-python programs may need to talk to zlock still (such as BIAS), and it will be a pain in the neck for them to require encryption to do so. And unlike the arbitrary code execution allowed by the remote process server, the threat model of \"someone can temporarily ask politely for other programs not to open a HDF5 file if they know its exact name\" doesn't exactly have me shaking in my boots.\r\n\r\nSo I'm undecided about how to resolve this. Two options are:\r\n\r\n1. Add a setting to labconfig to leave zlock, specifically, unencrypted\r\n2. Make a proxy script that can run locally that forwards an unencrypted zmq REQ socket to a remote encrypted zmq REP socket. This could be used to allow programs like BIAS to talk to an encrypted zlock server.\r\n\r\nThis is exluding the third option where people with programs like BIAS just run with `allow_insecure = True` all the time - that strikes me as not a good plan.\r\n\r\nBoth of these options are easy to implement. The latter would likely mean adding another port number in labconfig for the local zlock proxy, and then the proxy would be started with something like `python -m labscript_utils.zlockproxy`. BIAS would then need to be modified to talk to localhost and that port number instead of a remote zlock server.\r\n\r\nThere is no particular reason for *logging* to be encrypted either given what it is, but I find it unappealing to have *some* connections encrypted and some not - this strikes me as more bug-prone than having *everything* encrypted. This is the main point against having zlock be an exception.\r\n\r\nInterested in people's thoughts, including @lincolndturner if you have any opinion here.\r\n\r\nA final option is that it might be possible to configure zlock to accept both encrypted and unencrypted traffic. This would be fairly ideal (so long as it optional so that people thinking they're using secure communication aren't misled), but zmq authentication is hard so it will be some effort to figure out if this is possible and implement it.", "title": "Implement remote workers in BLACS", "destination": {"commit": {"hash": "5d54c0612c8c", "type": "commit", "links": {"self": {"href": "data/repositories/labscript_suite/blacs/commit/5d54c0612c8c.json"}, "html": {"href": "#!/labscript_suite/blacs/commits/5d54c0612c8c"}}}, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/blacs.json"}, "html": {"href": "#!/labscript_suite/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}ts=249915"}}, "type": "repository", "name": "BLACS", "full_name": "labscript_suite/blacs", "uuid": "{50ed1eb9-8c1b-4afe-a8b8-8e0a33b39a05}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "f1307f170c5a", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/cbillington/blacs/commit/f1307f170c5a"}, "html": {"href": "#!/cbillington/blacs/commits/f1307f170c5a"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/cbillington/blacs"}, "html": {"href": "#!/cbillington/blacs"}, "avatar": {"href": "data/bytebucket.org/ravatar/{1ffc697c-0cdc-43c3-b124-343fa9d9cc95}ts=python"}}, "type": "repository", "name": "BLACS", "full_name": "cbillington/blacs", "uuid": "{1ffc697c-0cdc-43c3-b124-343fa9d9cc95}"}, "branch": {"name": "remote-workers"}}, "state": "OPEN", "author": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "date": "2019-04-24T18:13:30.856772+00:00"}, "pull_request": {"type": "pullrequest", "id": 67, "links": {"self": {"href": "data/repositories/labscript_suite/blacs/pullrequests/67.json"}, "html": {"href": "#!/labscript_suite/blacs/pull-requests/67"}}, "title": "Implement remote workers in BLACS"}}]}