{"priority": "major", "kind": "enhancement", "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/labscript.json"}, "html": {"href": "#!/labscript_suite/labscript"}, "avatar": {"href": "data/bytebucket.org/ravatar/{48848b08-1db5-463b-bbdc-911beadf8bbf}ts=249917"}}, "type": "repository", "name": "labscript", "full_name": "labscript_suite/labscript", "uuid": "{48848b08-1db5-463b-bbdc-911beadf8bbf}"}, "links": {"attachments": {"href": "data/repositories/labscript_suite/labscript/issues/41/attachments_page=1.json"}, "self": {"href": "data/repositories/labscript_suite/labscript/issues/41.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/labscript_suite/labscript/issues/41/watch"}, "comments": {"href": "data/repositories/labscript_suite/labscript/issues/41/comments_page=1.json"}, "html": {"href": "#!/labscript_suite/labscript/issues/41/test-suite-for-labscript"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/labscript_suite/labscript/issues/41/vote"}}, "reporter": {"display_name": "Philip Starkey", "uuid": "{48af65db-e5fc-459c-a7eb-52eb1f9a5690}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B48af65db-e5fc-459c-a7eb-52eb1f9a5690%7D"}, "html": {"href": "https://bitbucket.org/%7B48af65db-e5fc-459c-a7eb-52eb1f9a5690%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/dc318537facc47ebe1ae98a7aabacecfd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsPS-0.png"}}, "nickname": "pstarkey", "type": "user", "account_id": "557058:52a111e4-40da-4441-9143-417f95f2db97"}, "title": "Test suite for labscript", "component": null, "votes": 1, "watches": 2, "content": {"raw": "Changes to labscript that contain unexpected bugs, risk breaking people's experiments. Worse, a mistake could adversely affect the ability to obtain scientific results, or even invalidate publications. Corner cases are often hard to catch during testing, and may persist for years. To combat this, we should implement a test suite.\r\n\r\nI suggest that we expose the runviewer `Shot` class in an API and use the traces (that are reverse engineered from the hardware instructions stored in the hdf5 file) to verify that outputs still maintain the same behaviour after labscript changes.\r\n\r\nWe should also:\r\n\r\n* have something in the test suite that detects ramps, and warns (but not fails) the test if the clock ticks (and thus the ramp evaluation points) have changed slightly.\r\n* Determines if part of the trace is just shifted in time (so that we can determine if the shift is expected - e.g. because we increased the trigger time when fixing a bug)\r\n* Create a comprehensive test shot that uses all standard hardware, along with expected traces (generated by hand, so that the test does not fail (or worse, pass) due to a mistake in the runviewer API) to be used before merging pull requests.\r\n* use mercurial to pull the expected behaviour of past versions for comparison with the expected behaviour of the current version", "markup": "markdown", "html": "<p>Changes to labscript that contain unexpected bugs, risk breaking people's experiments. Worse, a mistake could adversely affect the ability to obtain scientific results, or even invalidate publications. Corner cases are often hard to catch during testing, and may persist for years. To combat this, we should implement a test suite.</p>\n<p>I suggest that we expose the runviewer <code>Shot</code> class in an API and use the traces (that are reverse engineered from the hardware instructions stored in the hdf5 file) to verify that outputs still maintain the same behaviour after labscript changes.</p>\n<p>We should also:</p>\n<ul>\n<li>have something in the test suite that detects ramps, and warns (but not fails) the test if the clock ticks (and thus the ramp evaluation points) have changed slightly.</li>\n<li>Determines if part of the trace is just shifted in time (so that we can determine if the shift is expected - e.g. because we increased the trigger time when fixing a bug)</li>\n<li>Create a comprehensive test shot that uses all standard hardware, along with expected traces (generated by hand, so that the test does not fail (or worse, pass) due to a mistake in the runviewer API) to be used before merging pull requests.</li>\n<li>use mercurial to pull the expected behaviour of past versions for comparison with the expected behaviour of the current version</li>\n</ul>", "type": "rendered"}, "assignee": null, "state": "new", "version": null, "edited_on": null, "created_on": "2017-06-28T04:54:06.313879+00:00", "milestone": null, "updated_on": "2017-06-28T04:55:51.473040+00:00", "type": "issue", "id": 41}