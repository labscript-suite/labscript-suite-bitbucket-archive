{"priority": "major", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/labscript_utils.json"}, "html": {"href": "#!/labscript_suite/labscript_utils"}, "avatar": {"href": "data/bytebucket.org/ravatar/{68347210-fb1e-4b58-86c0-bd2c04396e63}ts=249922"}}, "type": "repository", "name": "labscript_utils", "full_name": "labscript_suite/labscript_utils", "uuid": "{68347210-fb1e-4b58-86c0-bd2c04396e63}"}, "links": {"attachments": {"href": "data/repositories/labscript_suite/labscript_utils/issues/21/attachments_page=1.json"}, "self": {"href": "data/repositories/labscript_suite/labscript_utils/issues/21.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/labscript_suite/labscript_utils/issues/21/watch"}, "comments": {"href": "data/repositories/labscript_suite/labscript_utils/issues/21/comments_page=1.json"}, "html": {"href": "#!/labscript_suite/labscript_utils/issues/21/concurrent-log-handler-causes-unbearable"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/labscript_suite/labscript_utils/issues/21/vote"}}, "reporter": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "title": "Concurrent log handler causes unbearable slowdown", "component": null, "votes": 0, "watches": 1, "content": {"raw": "BLACS is intolerably slow to do anything when using the concurrent log handler introduced to fix the logging bug. I suppose all that file opening and closing as the processes exchange locks is is just too much. Toggling a digital out takes ~1 second with all the logging we do, whereas with regular logging it takes ~30ms. This latency adds up everywhere in BLACS, reducing shot throughput and making everything you do a little sluggish.\r\n\r\nSo back to the drawing board with logging - I'll probably subclass a logging handler to send data over zeromq to a server a-la zlock, which was the original plan.\r\n\r\nThis sluggishness was observed in Windows 10 and is clearly gone if the logging is switched back to a regular FileHandler. I don't observe the problem on linux.", "markup": "markdown", "html": "<p>BLACS is intolerably slow to do anything when using the concurrent log handler introduced to fix the logging bug. I suppose all that file opening and closing as the processes exchange locks is is just too much. Toggling a digital out takes ~1 second with all the logging we do, whereas with regular logging it takes ~30ms. This latency adds up everywhere in BLACS, reducing shot throughput and making everything you do a little sluggish.</p>\n<p>So back to the drawing board with logging - I'll probably subclass a logging handler to send data over zeromq to a server a-la zlock, which was the original plan.</p>\n<p>This sluggishness was observed in Windows 10 and is clearly gone if the logging is switched back to a regular FileHandler. I don't observe the problem on linux.</p>", "type": "rendered"}, "assignee": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "state": "resolved", "version": null, "edited_on": null, "created_on": "2018-09-20T19:19:29.887387+00:00", "milestone": null, "updated_on": "2019-02-05T20:02:19.027656+00:00", "type": "issue", "id": 21}