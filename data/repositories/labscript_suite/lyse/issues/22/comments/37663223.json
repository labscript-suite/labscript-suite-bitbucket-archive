{"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/22/comments/37663223.json"}, "html": {"href": "#!/labscript_suite/lyse/issues/22#comment-37663223"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/22.json"}}, "type": "issue", "id": 22, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse.json"}, "html": {"href": "#!/labscript_suite/lyse"}, "avatar": {"href": "data/bytebucket.org/ravatar/{55eebdfe-43d1-4ae8-9049-50c55b295397}ts=249921"}}, "type": "repository", "name": "lyse", "full_name": "labscript_suite/lyse", "uuid": "{55eebdfe-43d1-4ae8-9049-50c55b295397}"}, "title": "Allow Multishot Routines to add to dataframe"}, "content": {"raw": "It wouldn't be a Qt signal, as analysis routines are actually running in their own subprocess even when lyse is running them. I do have an interprocess signal system that we use for some things like that, but I think the solution is much simpler. The analysis subprocess already needs to say \"done\" to lyse - it would now say \"done, and by the way, here is a dictionary of values you should update or add to your dataframe\". The dictionary would be added to in each call to Run.save_result() if spinning_top was True. The dictionary itself would live in the lyse module, but probably be None or not exist if not running from within lyse. The wrapper code that calls your analysis routine would reset the dictionary to an empty one prior to each run of your code.\n\nThen lyse would need to grow a little bit of code to update the dataframe and GUI with this data.\n\nI see no remaining problems with implementing the feature this way, and I'm happy to do the coding for it, though I can't of course guarantee when! This change would I think speed up the simplest single-shot analyses for everyone quite a bit, since lyse would no longer need to read the HDF5 file after each one.", "markup": "markdown", "html": "<p>It wouldn't be a Qt signal, as analysis routines are actually running in their own subprocess even when lyse is running them. I do have an interprocess signal system that we use for some things like that, but I think the solution is much simpler. The analysis subprocess already needs to say \"done\" to lyse - it would now say \"done, and by the way, here is a dictionary of values you should update or add to your dataframe\". The dictionary would be added to in each call to Run.save_result() if spinning_top was True. The dictionary itself would live in the lyse module, but probably be None or not exist if not running from within lyse. The wrapper code that calls your analysis routine would reset the dictionary to an empty one prior to each run of your code.</p>\n<p>Then lyse would need to grow a little bit of code to update the dataframe and GUI with this data.</p>\n<p>I see no remaining problems with implementing the feature this way, and I'm happy to do the coding for it, though I can't of course guarantee when! This change would I think speed up the simplest single-shot analyses for everyone quite a bit, since lyse would no longer need to read the HDF5 file after each one.</p>", "type": "rendered"}, "created_on": "2017-06-17T19:58:24.975809+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 37663223}