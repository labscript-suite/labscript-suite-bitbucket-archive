{"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/29/comments/38288240.json"}, "html": {"href": "#!/labscript_suite/lyse/issues/29#comment-38288240"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse.json"}, "html": {"href": "#!/labscript_suite/lyse"}, "avatar": {"href": "data/bytebucket.org/ravatar/{55eebdfe-43d1-4ae8-9049-50c55b295397}ts=249921"}}, "type": "repository", "name": "lyse", "full_name": "labscript_suite/lyse", "uuid": "{55eebdfe-43d1-4ae8-9049-50c55b295397}"}, "title": "speed up shot loading"}, "content": {"raw": "Currently I'm not checking if the files still exist/have changed etc. I'm just splitting tha dataframe by sequences and exporting it into a hdf5 file on press of a button. The hdf5 file however to net get confused is saved with the file ending .df . I'm using DataFrame.to_hdf and pandas.read_hdf for this.\n\nThis is mainly useful when measuring lots of sequences over night. We then export the dataframe(s) and load in the individual sequences one after the other as this is a lot faster than loading the files. Also after things are done we overwrite the old dataframe with a updated version. \nAs loading a dataframe like this only takes up about 5 seconds one can take a quick look at old data or quickly run some new routines without the hassle of waiting for up to 15 minutes.\n\n\nAlso here is the result of your profiler running on add_files:\n![example.png](data/bitbucket.org/repo/BMBAeq/images/4234763019-example.png)\nHaven't really looked at it much but if I interpret it correctly scientific_notation and get_model_row_by_filepath seems to be slow.", "markup": "markdown", "html": "<p>Currently I'm not checking if the files still exist/have changed etc. I'm just splitting tha dataframe by sequences and exporting it into a hdf5 file on press of a button. The hdf5 file however to net get confused is saved with the file ending .df . I'm using DataFrame.to_hdf and pandas.read_hdf for this.</p>\n<p>This is mainly useful when measuring lots of sequences over night. We then export the dataframe(s) and load in the individual sequences one after the other as this is a lot faster than loading the files. Also after things are done we overwrite the old dataframe with a updated version. \nAs loading a dataframe like this only takes up about 5 seconds one can take a quick look at old data or quickly run some new routines without the hassle of waiting for up to 15 minutes.</p>\n<p>Also here is the result of your profiler running on add_files:\n<img alt=\"example.png\" src=\"data/bitbucket.org/repo/BMBAeq/images/4234763019-example.png\" />\nHaven't really looked at it much but if I interpret it correctly scientific_notation and get_model_row_by_filepath seems to be slow.</p>", "type": "rendered"}, "created_on": "2017-07-17T20:24:22.912917+00:00", "user": {"display_name": "Jan Werkmann", "uuid": "{44c4905c-2b90-4045-a5f1-652b8e228626}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B44c4905c-2b90-4045-a5f1-652b8e228626%7D"}, "html": {"href": "https://bitbucket.org/%7B44c4905c-2b90-4045-a5f1-652b8e228626%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:a70cc9cf-684e-4849-a61a-9ade4d7218b5/07e5095a-4741-4dc0-a462-9c7d455f961d/128"}}, "nickname": "PhyNerd", "type": "user", "account_id": "557058:a70cc9cf-684e-4849-a61a-9ade4d7218b5"}, "updated_on": null, "type": "issue_comment", "id": 38288240}