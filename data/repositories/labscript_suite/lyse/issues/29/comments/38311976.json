{"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/29/comments/38311976.json"}, "html": {"href": "#!/labscript_suite/lyse/issues/29#comment-38311976"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse/issues/29.json"}}, "type": "issue", "id": 29, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/lyse.json"}, "html": {"href": "#!/labscript_suite/lyse"}, "avatar": {"href": "data/bytebucket.org/ravatar/{55eebdfe-43d1-4ae8-9049-50c55b295397}ts=249921"}}, "type": "repository", "name": "lyse", "full_name": "labscript_suite/lyse", "uuid": "{55eebdfe-43d1-4ae8-9049-50c55b295397}"}, "title": "speed up shot loading"}, "content": {"raw": "There is also about 30% of `update_row()` missing in the percentages, which makes me think that that 30% is made up of many small things none of which is above 5% of run time (BProfile has a default threshold of 5% but you can set it smaller to see more detail). That as well as the visible places it is spending time make me think that unfortunately we're running out of places to optimise without a more radical change. So chipping away at scientific_notation() could be good (possible low hanging fruit - move the constants to the global namespace rather than defining them within the function?), but there's diminishing returns in optimising things more as they are.\n\nSo a more radical change would be to look into how Qt models work and subclass it to be backed by the dataframe itself, with the tooltips and scientific notation all being computed lazily only when the method to get that data was called (indicating the column was actually visible or the user had actually moused-over for a tooltip) and possibly  cached. This was originally suggested by @philipstarkey when we began porting to Qt, and I don't recall why I didn't go for it. In any case the code is organised well enough that the change would be isolated to the `DataFrameModel` class (the name maybe hints that I was initially going to go with phil's suggestion but gave up because it looked too tricky?).\n\nThat could be something to look into for the future, but these optimisations should be included now anyway!\n\nI'm a little skeptical about the profiling results, surprised to not see much in the way of Qt calls in there. Maybe Qt is just really fast, but it's also the case that sometimes the profiler doesn't catch certain things - like I'm not sure if the creation of constants like the dictionaries and string constants in `scientific_notation` would appear in the profiling results. I have another profiling tool that measures what percentage of the time is spent on each *line* of a given file rather than profiling in terms of function calls, which I have found to be super useful, but at the moment this tool is a pile of platform-specific hacks rather than something I could distribute. But I'll think about getting it into shape so we can do some better profiling since performance is so important to people with so many shots.\n\nI think you should feel free to make a pull request even if you think something isn't \"ready\" yet. Pull requests are more visible in the bitbucket UI and are a nice way to see what things are \"in progress\" from other people's forks. Pull requests have the diff and list of commits visible and have nested comment threads (which issue threads frustratingly lack). They also have the source branch listed so people can see where to pull from for testing without you having to tell us. Just mention in the pull request that you're still looking for feedback and we won't merge - even if you don't mention anything, most things won't be merged without some comments anyway about testing etc. We can always just reject a pull request if an approach is abandoned.", "markup": "markdown", "html": "<p>There is also about 30% of <code>update_row()</code> missing in the percentages, which makes me think that that 30% is made up of many small things none of which is above 5% of run time (BProfile has a default threshold of 5% but you can set it smaller to see more detail). That as well as the visible places it is spending time make me think that unfortunately we're running out of places to optimise without a more radical change. So chipping away at scientific_notation() could be good (possible low hanging fruit - move the constants to the global namespace rather than defining them within the function?), but there's diminishing returns in optimising things more as they are.</p>\n<p>So a more radical change would be to look into how Qt models work and subclass it to be backed by the dataframe itself, with the tooltips and scientific notation all being computed lazily only when the method to get that data was called (indicating the column was actually visible or the user had actually moused-over for a tooltip) and possibly  cached. This was originally suggested by @philipstarkey when we began porting to Qt, and I don't recall why I didn't go for it. In any case the code is organised well enough that the change would be isolated to the <code>DataFrameModel</code> class (the name maybe hints that I was initially going to go with phil's suggestion but gave up because it looked too tricky?).</p>\n<p>That could be something to look into for the future, but these optimisations should be included now anyway!</p>\n<p>I'm a little skeptical about the profiling results, surprised to not see much in the way of Qt calls in there. Maybe Qt is just really fast, but it's also the case that sometimes the profiler doesn't catch certain things - like I'm not sure if the creation of constants like the dictionaries and string constants in <code>scientific_notation</code> would appear in the profiling results. I have another profiling tool that measures what percentage of the time is spent on each <em>line</em> of a given file rather than profiling in terms of function calls, which I have found to be super useful, but at the moment this tool is a pile of platform-specific hacks rather than something I could distribute. But I'll think about getting it into shape so we can do some better profiling since performance is so important to people with so many shots.</p>\n<p>I think you should feel free to make a pull request even if you think something isn't \"ready\" yet. Pull requests are more visible in the bitbucket UI and are a nice way to see what things are \"in progress\" from other people's forks. Pull requests have the diff and list of commits visible and have nested comment threads (which issue threads frustratingly lack). They also have the source branch listed so people can see where to pull from for testing without you having to tell us. Just mention in the pull request that you're still looking for feedback and we won't merge - even if you don't mention anything, most things won't be merged without some comments anyway about testing etc. We can always just reject a pull request if an approach is abandoned.</p>", "type": "rendered"}, "created_on": "2017-07-18T18:41:32.609399+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": null, "type": "issue_comment", "id": 38311976}