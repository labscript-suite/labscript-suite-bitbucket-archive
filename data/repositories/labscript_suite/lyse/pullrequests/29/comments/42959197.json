{"links": {"self": {"href": "data/repositories/labscript_suite/lyse/pullrequests/29/comments/42959197.json"}, "html": {"href": "#!/labscript_suite/lyse/pull-requests/29/_/diff#comment-42959197"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 29, "links": {"self": {"href": "data/repositories/labscript_suite/lyse/pullrequests/29.json"}, "html": {"href": "#!/labscript_suite/lyse/pull-requests/29"}}, "title": "Cross routine caching"}, "content": {"raw": "This issue is a bit more general and I wonder if we can work out a more general fix. \n\nThe problem is that whilst operating systems are clever about caching file access such that it is usually pointless to \"cache\" something that you wrote to a file (my original objection to any feature like this being neccesary), it turns out that this does not apply to network drives.\n\nEvery access to a network drive is a new read, even if the data on the drive has not changed, even if the file's modified time has not changed. Operating systems do not cache the data locally.\n\nSo I wonder if we can do something a bit more general, such as having an option for lyse to make a local copy of every HDF5 file that comes in, copying it back to the network drive only once analysis has completed, or something like that.\n\nA workaround I suspect would work as well is to have the shared drive be hosted on the computer running lyse.\n\nAn even more general solution might involve a general purpose monkeypatch to h5py that would keep a cache of local files up to some limit (set by the computer's RAM probably, since the OS won't cache more than that) and upon file open in read-only mode, would go out to the network drive and check the file modified time, returning the on-disk cached version if it is up to date, and updating the cache before returning it if not. There are downsides to this - you are copying data locally that you don't need a lot of the time, but I'll put some thought into it and maybe we can work something out that will solve this problem without having to abandon the files being authoritative.\n\nIt might even be possible to intercept h5py's opening of files at a low enough level that we could cache only locally written data and not have to copy over data from the network that isn't being read. I'm talking \"you want to read byte 785 of the file? I have byte 785 right here...\" rather than talking in terms of datasets or anything else to do with HDF5. After all, this is how operating system caches work, and they seem to work fine for HDF5 files when they are stored locally on disk. This would be my preferred solution so far.", "markup": "markdown", "html": "<p>This issue is a bit more general and I wonder if we can work out a more general fix. </p>\n<p>The problem is that whilst operating systems are clever about caching file access such that it is usually pointless to \"cache\" something that you wrote to a file (my original objection to any feature like this being neccesary), it turns out that this does not apply to network drives.</p>\n<p>Every access to a network drive is a new read, even if the data on the drive has not changed, even if the file's modified time has not changed. Operating systems do not cache the data locally.</p>\n<p>So I wonder if we can do something a bit more general, such as having an option for lyse to make a local copy of every HDF5 file that comes in, copying it back to the network drive only once analysis has completed, or something like that.</p>\n<p>A workaround I suspect would work as well is to have the shared drive be hosted on the computer running lyse.</p>\n<p>An even more general solution might involve a general purpose monkeypatch to h5py that would keep a cache of local files up to some limit (set by the computer's RAM probably, since the OS won't cache more than that) and upon file open in read-only mode, would go out to the network drive and check the file modified time, returning the on-disk cached version if it is up to date, and updating the cache before returning it if not. There are downsides to this - you are copying data locally that you don't need a lot of the time, but I'll put some thought into it and maybe we can work something out that will solve this problem without having to abandon the files being authoritative.</p>\n<p>It might even be possible to intercept h5py's opening of files at a low enough level that we could cache only locally written data and not have to copy over data from the network that isn't being read. I'm talking \"you want to read byte 785 of the file? I have byte 785 right here...\" rather than talking in terms of datasets or anything else to do with HDF5. After all, this is how operating system caches work, and they seem to work fine for HDF5 files when they are stored locally on disk. This would be my preferred solution so far.</p>", "type": "rendered"}, "created_on": "2017-08-16T20:34:48.013765+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": "2017-08-16T20:38:01.146151+00:00", "type": "pullrequest_comment", "id": 42959197}