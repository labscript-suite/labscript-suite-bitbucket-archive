{"links": {"self": {"href": "data/repositories/labscript_suite/runmanager/issues/66/comments/51386107.json"}, "html": {"href": "#!/labscript_suite/runmanager/issues/66#comment-51386107"}}, "issue": {"links": {"self": {"href": "data/repositories/labscript_suite/runmanager/issues/66.json"}}, "type": "issue", "id": 66, "repository": {"links": {"self": {"href": "data/repositories/labscript_suite/runmanager.json"}, "html": {"href": "#!/labscript_suite/runmanager"}, "avatar": {"href": "data/bytebucket.org/ravatar/{9b4f21e6-54b0-41ea-8f01-db1919f2f790}ts=249918"}}, "type": "repository", "name": "runmanager", "full_name": "labscript_suite/runmanager", "uuid": "{9b4f21e6-54b0-41ea-8f01-db1919f2f790}"}, "title": "Preparse thread memory leak/crash"}, "content": {"raw": "The issue is independent of Python 2 vs Python 3.\n\nI have to revert back to version 2.1.0, just before the merge of pull request #15 before it works again.\n\nHowever, if I then update back to the latest version, the issue no longer occurs. This is because version 2.1.0 *modifies the names of the zip groups*, presumably erroneously since pull request #15 is called \"Fixed several bugs where custom zip groups were overridden.\" So that means there's some hysteresis to the testing...I'm having to restore the h5 file in between each test. It also means 2.1.0 is probably not actually immune to the problem, it's just not hitting on the conditions that trigger it since it modified the zip groups. So this seems at odds with you seeing things working before updating from the commit at pull request #27, so something else must have changed as well.\n\nFor anyone else interested, here's a screenshot of the offending group:\n\n![Screenshot from 2019-03-28 18-30-57.png](data/bitbucket.org/repo/6g5bg5/images/3682164210-Screenshot_from_2019-03-28_18-30-57.png)\n\nActivating just this group causes the crash - takes about 20 seconds to fill my computer's 32GB of memory before the OS kills it.\n\nIt's pretty compex, I'm definitely not able to tell how many shots this results in by looking at it. You've got six axes, lots of references, one global is an array that is the concatenation of three of the others. No wonder we didn't see this elsewhere! My guess is that runmanager is interpreting one of these arrays as being extremely large such that it doesn't fit in memory.\n\nFurther debugging reveals that runmanager is choking on expanding the outer product over all axes - it interprets the above as describing 57,600,000 shots, so no wonder. \n\nThe axes are as follows:\n```\n      zip Res_regime n =  40\n                zip  n =  1\n       zip AC_regime n =  60\n      zip uWave_scan n =  120\n         zip resDets n =  10\n     zip High_regime n =  20\n```\n\n(the unnamed zip group with n=1 must be the globals not in any group, not sure).\n\nIf this isn't the result you were going for, can you tell what dimensions runmanager should have gotten?\n\nOr perhaps runmanager changed the expansion settings, and when set back to what they should be, it doesn't choke on them?\n\nIf you want to debug further (or just recover from the situation) you can modify runmanager's default saved config file (<experiment_shot_storage>/runmanager.ini) and deactivate the groups (or just rename the config file so runmanager starts up fresh). You can then open the globals file in a fresh runmanager, and modify the values before setting the group to be active. The preparser won't touch it if it's inactive.", "markup": "markdown", "html": "<p>The issue is independent of Python 2 vs Python 3.</p>\n<p>I have to revert back to version 2.1.0, just before the merge of <a href=\"#!/labscript_suite/runmanager/pull-requests/15/fixed-several-bugs-where-custom-zip-groups\" rel=\"nofollow\" class=\"ap-connect-link\">pull request #15</a> before it works again.</p>\n<p>However, if I then update back to the latest version, the issue no longer occurs. This is because version 2.1.0 <em>modifies the names of the zip groups</em>, presumably erroneously since <a href=\"#!/labscript_suite/runmanager/pull-requests/15/fixed-several-bugs-where-custom-zip-groups\" rel=\"nofollow\" class=\"ap-connect-link\">pull request #15</a> is called \"Fixed several bugs where custom zip groups were overridden.\" So that means there's some hysteresis to the testing...I'm having to restore the h5 file in between each test. It also means 2.1.0 is probably not actually immune to the problem, it's just not hitting on the conditions that trigger it since it modified the zip groups. So this seems at odds with you seeing things working before updating from the commit at <a href=\"#!/labscript_suite/runmanager/pull-requests/27/splash-screen\" rel=\"nofollow\" class=\"ap-connect-link\">pull request #27</a>, so something else must have changed as well.</p>\n<p>For anyone else interested, here's a screenshot of the offending group:</p>\n<p><img alt=\"Screenshot from 2019-03-28 18-30-57.png\" src=\"data/bitbucket.org/repo/6g5bg5/images/3682164210-Screenshot_from_2019-03-28_18-30-57.png\" /></p>\n<p>Activating just this group causes the crash - takes about 20 seconds to fill my computer's 32GB of memory before the OS kills it.</p>\n<p>It's pretty compex, I'm definitely not able to tell how many shots this results in by looking at it. You've got six axes, lots of references, one global is an array that is the concatenation of three of the others. No wonder we didn't see this elsewhere! My guess is that runmanager is interpreting one of these arrays as being extremely large such that it doesn't fit in memory.</p>\n<p>Further debugging reveals that runmanager is choking on expanding the outer product over all axes - it interprets the above as describing 57,600,000 shots, so no wonder. </p>\n<p>The axes are as follows:</p>\n<div class=\"codehilite\"><pre><span></span>      zip Res_regime n =  40\n                zip  n =  1\n       zip AC_regime n =  60\n      zip uWave_scan n =  120\n         zip resDets n =  10\n     zip High_regime n =  20\n</pre></div>\n\n\n<p>(the unnamed zip group with n=1 must be the globals not in any group, not sure).</p>\n<p>If this isn't the result you were going for, can you tell what dimensions runmanager should have gotten?</p>\n<p>Or perhaps runmanager changed the expansion settings, and when set back to what they should be, it doesn't choke on them?</p>\n<p>If you want to debug further (or just recover from the situation) you can modify runmanager's default saved config file (&lt;experiment_shot_storage&gt;/runmanager.ini) and deactivate the groups (or just rename the config file so runmanager starts up fresh). You can then open the globals file in a fresh runmanager, and modify the values before setting the group to be active. The preparser won't touch it if it's inactive.</p>", "type": "rendered"}, "created_on": "2019-03-28T23:01:28.197485+00:00", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}, "updated_on": "2019-03-28T23:02:45.217449+00:00", "type": "issue_comment", "id": 51386107}