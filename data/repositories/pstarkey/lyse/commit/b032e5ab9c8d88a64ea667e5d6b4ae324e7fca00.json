{"rendered": {"message": {"raw": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "markup": "markdown", "html": "<p>Performance optimisation.</p>\n<ul>\n<li>\n<p>lookup rows in dataframe by filepath using a dictionary cache rather<br />\n  than searching the dataframe. This removes the need for the method<br />\n  get_model_row_by_filepath(), so it has been removed and the dictionary used<br />\n  directly.</p>\n</li>\n<li>\n<p>Remove redundant getting of the row index again for the Qt model - it is<br />\n  the same row as the dataframe</p>\n</li>\n<li>\n<p>Avoid setting the text of a QStandardItem twice by only creating it once<br />\n  the text it should have is known</p>\n</li>\n<li>\n<p>Add an argument to renumber_rows() that allows it to only renumber recent<br />\n  rows for the case that new rows have been added and don't have numbers yet<br />\n  but the existing row numbers are still valid</p>\n</li>\n<li>\n<p>Modify batch processing of shot files to use a dynamic batch size, with<br />\n  larger batches the more shots lyse has loaded. This is a good tradeoff<br />\n  between GUI responsiveness when there are a small number of shot files<br />\n  and speed when loading a large number of shot files. The batch size is 1/3<br />\n  of the number of shots. Larger batch sizes mean less redundant concatenation<br />\n  of dataframes.</p>\n</li>\n<li>\n<p>Modify the progress bar message to say when it's reading shot files<br />\n  vs concatenating dataframes vs updating the filebox GUI.</p>\n</li>\n</ul>", "type": "rendered"}}, "hash": "b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00", "repository": {"links": {"self": {"href": "data/repositories/pstarkey/lyse.json"}, "html": {"href": "#!/pstarkey/lyse"}, "avatar": {"href": "data/bytebucket.org/ravatar/{e5413385-6166-4d2c-9b39-d34598d7fb72}ts=python"}}, "type": "repository", "name": "lyse", "full_name": "pstarkey/lyse", "uuid": "{e5413385-6166-4d2c-9b39-d34598d7fb72}"}, "links": {"self": {"href": "data/repositories/pstarkey/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00.json"}, "comments": {"href": "data/repositories/pstarkey/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/comments_page=1.json"}, "patch": {"href": "https://api.bitbucket.org/2.0/repositories/pstarkey/lyse/patch/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "html": {"href": "#!/pstarkey/lyse/commits/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "diff": {"href": "https://api.bitbucket.org/2.0/repositories/pstarkey/lyse/diff/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00"}, "approve": {"href": "https://api.bitbucket.org/2.0/repositories/pstarkey/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/approve"}, "statuses": {"href": "data/repositories/pstarkey/lyse/commit/b032e5ab9c8d88a64ea667e5d6b4ae324e7fca00/statuses_page=1.json"}}, "author": {"raw": "chrisjbillington", "type": "author", "user": {"display_name": "Chris Billington", "uuid": "{e363c5a9-5075-4656-afb5-88bd6a6dceeb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D"}, "html": {"href": "https://bitbucket.org/%7Be363c5a9-5075-4656-afb5-88bd6a6dceeb%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/9238baf7300c41c0e7294db922899e6ad=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCB-1.png"}}, "nickname": "cbillington", "type": "user", "account_id": "557058:cbf1bc43-1dc2-477b-9e25-1a8f40fd7ee3"}}, "summary": {"raw": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "markup": "markdown", "html": "<p>Performance optimisation.</p>\n<ul>\n<li>\n<p>lookup rows in dataframe by filepath using a dictionary cache rather<br />\n  than searching the dataframe. This removes the need for the method<br />\n  get_model_row_by_filepath(), so it has been removed and the dictionary used<br />\n  directly.</p>\n</li>\n<li>\n<p>Remove redundant getting of the row index again for the Qt model - it is<br />\n  the same row as the dataframe</p>\n</li>\n<li>\n<p>Avoid setting the text of a QStandardItem twice by only creating it once<br />\n  the text it should have is known</p>\n</li>\n<li>\n<p>Add an argument to renumber_rows() that allows it to only renumber recent<br />\n  rows for the case that new rows have been added and don't have numbers yet<br />\n  but the existing row numbers are still valid</p>\n</li>\n<li>\n<p>Modify batch processing of shot files to use a dynamic batch size, with<br />\n  larger batches the more shots lyse has loaded. This is a good tradeoff<br />\n  between GUI responsiveness when there are a small number of shot files<br />\n  and speed when loading a large number of shot files. The batch size is 1/3<br />\n  of the number of shots. Larger batch sizes mean less redundant concatenation<br />\n  of dataframes.</p>\n</li>\n<li>\n<p>Modify the progress bar message to say when it's reading shot files<br />\n  vs concatenating dataframes vs updating the filebox GUI.</p>\n</li>\n</ul>", "type": "rendered"}, "participants": [], "parents": [{"hash": "b90281ed62967638da073340fee577d2e532c1dd", "type": "commit", "links": {"self": {"href": "data/repositories/pstarkey/lyse/commit/b90281ed62967638da073340fee577d2e532c1dd.json"}, "html": {"href": "#!/pstarkey/lyse/commits/b90281ed62967638da073340fee577d2e532c1dd"}}}], "date": "2018-02-26T06:02:36+00:00", "message": "Performance optimisation.\n\n* lookup rows in dataframe by filepath using a dictionary cache rather\n  than searching the dataframe. This removes the need for the method\n  get_model_row_by_filepath(), so it has been removed and the dictionary used\n  directly.\n\n* Remove redundant getting of the row index again for the Qt model - it is\n  the same row as the dataframe\n\n* Avoid setting the text of a QStandardItem twice by only creating it once\n  the text it should have is known\n\n* Add an argument to renumber_rows() that allows it to only renumber recent\n  rows for the case that new rows have been added and don't have numbers yet\n  but the existing row numbers are still valid\n\n* Modify batch processing of shot files to use a dynamic batch size, with\n  larger batches the more shots lyse has loaded. This is a good tradeoff\n  between GUI responsiveness when there are a small number of shot files\n  and speed when loading a large number of shot files. The batch size is 1/3\n  of the number of shots. Larger batch sizes mean less redundant concatenation\n  of dataframes.\n\n* Modify the progress bar message to say when it's reading shot files\n  vs concatenating dataframes vs updating the filebox GUI.", "type": "commit", "git_hash": "86c988eb5edf68000c5e052a749ccddb1fca0519", "tags": null, "branches": "feature"}